# LLM Provider Configuration for Rotation Strategy
# Usage: Used by core/langchain_integration.py -> ProviderRotationManager
# Keys:
#   name: Identifier for logs
#   type: 'openai' or 'gemini'
#   model: Model name
#   api_key_env: Name of environment variable containing the key
#   base_url: Optional, for compatible APIs like Cerebras
#   priority: Lower number = tried first

providers:
  - name: cerebras
    type: openai
    model: llama-3.3-70b
    api_key_env: CEREBRAS_API_KEY
    base_url: https://api.cerebras.ai/v1
    priority: 1

  - name: cerebras
    type: openai
    model: qwen-3-235b-a22b-instruct-2507
    api_key_env: CEREBRAS_API_KEY
    base_url: https://api.cerebras.ai/v1
    priority: 2

  - name: cerebras
    type: openai
    model: gpt-oss-120b
    api_key_env: CEREBRAS_API_KEY
    base_url: https://api.cerebras.ai/v1
    priority: 3

  # - name: mistral
  #   type: openai
  #   model: codestral-latest
  #   api_key_env: CODESTRAL_API_KEY
  #   base_url: https://codestral.mistral.ai/v1
  #   priority: 4

  - name: nvidia
    type: openai
    model: meta/llama-3.3-70b-instruct
    base_url: https://integrate.api.nvidia.com/v1
    api_key_env: NVIDIA_API_KEY
    priority: 7

  - name: nvidia
    type: openai
    model: deepseek-ai/deepseek-r1
    base_url: https://integrate.api.nvidia.com/v1
    api_key_env: NVIDIA_API_KEY
    priority: 8

  # - name: gemini
  #   type: gemini
  #   model: gemma-3-27b
  #   api_key_env: GEMINI_API_KEY
  #   priority: 5

  - name: groq
    type: openai
    model: openai/gpt-oss-120b
    base_url: https://api.groq.com/openai/v1
    api_key_env: GROQ_API_KEY
    priority: 6